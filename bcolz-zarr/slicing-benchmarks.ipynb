{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Efficient storage and retrieval of large-scale multidimensional array data is a problem with many well-known solutions. More recently, a growing portion of the community has been shifting its focus to support cloud-based array data management, which presents new and different software engineering challenges.\n",
    "\n",
    "TileDB is a new array data management system with highly optimized support for cloud storage backends including AWS S3. TileDB offers fast reads, writes, and updates for array data stored locally or on the cloud, and numerous high-level language APIs including Python.\n",
    "\n",
    "In this notebook we compare TileDB's performance for reads and writes on AWS S3 with Zarr, an existing Python library for efficient compressed array data storage and retrieval. We show up to a ???x performance improvement over Zarr when writing array data to S3, and a ???x improvement when reading from S3.\n",
    "\n",
    "At the end we compare TileDB against Zarr for local disk (SSD) storage, and show comparable performance. For one-dimensional array data we also compare against bcolz, another Python library for compressed 1D array data storage and retrieval.\n",
    "\n",
    "All of the experiments in this notebook were run on an AWS EC2 `c5d.4xlarge` instance, which has 16 vCPUs, 32GB of RAM, and a 400GB dedicated SSD. The OS was Ubuntu 16.04.\n",
    "\n",
    "the machine used to run these experiments is a `c5d.4xlarge` instance on AWS EC2.\n",
    "\n",
    "due to the performance variability of EBS, we chose this instance for its dedicated SSD storage option. All experiments on local disk were run on the dedicated SSD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on S3\n",
    "\n",
    "To begin with, we'll import the modules we'll need, including TileDB, Zarr and bcolz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import bcolz\n",
    "import matplotlib.pyplot as plt\n",
    "import numcodecs\n",
    "import numpy as np\n",
    "import os\n",
    "import s3fs\n",
    "import shutil\n",
    "import subprocess\n",
    "import tiledb\n",
    "import time\n",
    "import zarr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benchmark data will be a 10,000x10,000 array of random 8-byte floating point values allocated using Numpy. Because the data is random, we won't expect to see much gain with compression by either system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_array_values = 10000, 10000\n",
    "array_data = np.random.rand(*num_array_values)\n",
    "print('2D array data is {:.2f} MB uncompressed.'.format(array_data.nbytes / (1024 * 1024.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we choose names for the arrays that will be stored, choose a compressor setting, and set up the S3 store for use with Zarr. \n",
    "\n",
    "When using TileDB for S3 interactions, the path to the array simply must have a URI prefix of `s3://`. TileDB interprets the URI prefix and interacts with the AWS S3 SDK as necessary for reads and writes, transparently to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tiledb.Config()\n",
    "s3_bucket_name = 'tiledb-bench'\n",
    "tiledb_array_name = 'tiledb_array'\n",
    "zarr_array_name =  'zarr_array'\n",
    "\n",
    "tiledb_compressor = ('blosc-lz4', 5)\n",
    "zarr_compressor = numcodecs.Blosc(cname='lz4', clevel=5)\n",
    "bcolz.defaults.cparams['cname'] = 'lz4'\n",
    "bcolz.defaults.cparams['clevel'] = 5\n",
    "\n",
    "zarr_s3 = s3fs.S3FileSystem(key=os.environ['AWS_ACCESS_KEY_ID'],\n",
    "                            secret=os.environ['AWS_SECRET_ACCESS_KEY'])\n",
    "zarr_s3_store = s3fs.S3Map(root=s3_bucket_name + '/' + zarr_array_name,\n",
    "                           s3=zarr_s3, check=False)\n",
    "zarr_array_path = zarr_s3_store\n",
    "tiledb_array_path = 's3://{}/{}'.format(s3_bucket_name, tiledb_array_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also define a helper function to remove the arrays so that we can run multiple iterations easily. Here we use TileDB's VFS class to perform the basic S3 filesystem operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_arrays():\n",
    "    ctx = tiledb.Ctx()\n",
    "    vfs = tiledb.VFS(ctx)\n",
    "    tiledb_uri = 's3://{}/{}'.format(s3_bucket_name, tiledb_array_name)\n",
    "    zarr_uri = 's3://{}/{}'.format(s3_bucket_name, zarr_array_name)\n",
    "    if vfs.is_dir(tiledb_uri):\n",
    "        vfs.remove_dir(tiledb_uri)\n",
    "    if vfs.is_dir(zarr_uri):\n",
    "        vfs.remove_dir(zarr_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array creation\n",
    "\n",
    "The first experiment will measure the time taken to create the 2D array on S3 for different tile sizes. Note that a \"tile extent\" in TileDB vocabulary is synonymous with a Zarr \"chunk.\"\n",
    "\n",
    "First we'll define helper functions to create the array on S3 with a given tile size. Note that TileDB has the extra step of defining an explicit \"array schema\" which controls things like the array dimensionality, domain size, and attributes.\n",
    "\n",
    "For convenience, we will also include a `sync` call, which flushes pending write data to local disk. While not necessary when storing to S3, this will ensure the local disk experiments include the time to flush the written data to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sync_fs():\n",
    "    \"Flushes pending writes to the local filesystem.\"\n",
    "    subprocess.check_call(['sudo', 'sync'])\n",
    "    \n",
    "\n",
    "def write_2d_tiledb_array(array_data, tile_extents):\n",
    "    shape = array_data.shape\n",
    "    ctx = tiledb.Ctx(config)\n",
    "    dom = tiledb.Domain(ctx,\n",
    "                        tiledb.Dim(ctx, domain=(0, shape[0] - 1), tile=tile_extents[0], dtype=np.uint32),\n",
    "                        tiledb.Dim(ctx, domain=(0, shape[1] - 1), tile=tile_extents[1], dtype=np.uint32))\n",
    "    schema = tiledb.ArraySchema(ctx, domain=dom, sparse=False,\n",
    "                                attrs=[tiledb.Attr(ctx, name='a', dtype=np.float64, compressor=tiledb_compressor)])\n",
    "    tiledb.DenseArray.create(tiledb_array_path, schema)\n",
    "    with tiledb.DenseArray(ctx, tiledb_array_path, mode='w') as A:\n",
    "        A[:] = array_data\n",
    "    sync_fs()\n",
    "\n",
    "\n",
    "def write_2d_zarr_array(array_data, tile_extents):\n",
    "    A = zarr.open(zarr_array_path, mode='w', compressor=zarr_compressor, shape=array_data.shape, chunks=tile_extents,\n",
    "                  dtype=np.float64)\n",
    "    A[:] = array_data\n",
    "    sync_fs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also define a helper function that will run a function several times and return the wall clock times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeit(fnc, setup=None, repeat=3):\n",
    "    \"Time a function's execution.\"\n",
    "    times = []\n",
    "    for i in range(0, repeat):\n",
    "        if setup is not None:\n",
    "            setup()\n",
    "        start = time.time()\n",
    "        fnc()\n",
    "        end = time.time()\n",
    "        times.append(end - start)\n",
    "    return times\n",
    "\n",
    "\n",
    "def plot_bars(times_per_library, title, xlabel, ylabel):\n",
    "    \"Creates a bar chart for timing comparisons.\"\n",
    "    colors = {'tiledb': '#27ace3', 'zarr': '#f9c22e', 'bcolz': '#9fffcb'}\n",
    "    bar_width = 0.25\n",
    "    xpos1 = np.arange(len(times_per_library['tiledb']))\n",
    "    xpos2 = xpos1 + bar_width\n",
    "    xpos3 = xpos2 + bar_width\n",
    "    xpos = [xpos1, xpos2, xpos3]\n",
    "    \n",
    "    plt.figure()\n",
    "    for i, key in enumerate(sorted(times_per_library.keys())):\n",
    "        plt.bar(xpos[i], times_per_library[key], color=colors[key], width=bar_width, label=key)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xticks(xpos1 + bar_width, tile_extents)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now create the array on S3 with the random data in `array_data` using both libraries, and plot the minimum wall clock time (in seconds) over 3 trials. We'll do this for We remove the array in between each trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_creation_times = {'tiledb': [], 'zarr': []}\n",
    "tile_extents = [(1000, 1000), (3000, 3000), (5000, 5000)]\n",
    "for t_ext in tile_extents:\n",
    "    array_creation_times['tiledb'].append(\n",
    "        min(timeit(lambda: write_2d_tiledb_array(array_data, t_ext), setup=remove_arrays, repeat=3)))\n",
    "    array_creation_times['zarr'].append(\n",
    "        min(timeit(lambda: write_2d_zarr_array(array_data, t_ext), setup=remove_arrays, repeat=3)))\n",
    "\n",
    "plot_bars(array_creation_times, 'S3 array creation time (2D, size {})'.format(num_array_values),\n",
    "          'Tile extent', 'Time (sec)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interpret above results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read performance\n",
    "\n",
    "Next we'll compare performance when reading from the array on S3 using TileDB and Zarr.\n",
    "\n",
    "To start, we'll issue a read operation of a single cell of the array. Because both TileDB and Zarr are chunked data formats, reading a single cell will require reading the entire chunk of data containing the cell. First we'll define two helper functions to read a specified region (\"subarray\") from the array using each library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tiledb_2d_subarray(subarray):\n",
    "    ctx = tiledb.Ctx(config)\n",
    "    with tiledb.DenseArray(ctx, tiledb_array_path, mode='r') as A:\n",
    "        data = A[subarray[0] : subarray[1], subarray[2] : subarray[3]]\n",
    "\n",
    "\n",
    "def read_zarr_2d_subarray(subarray):\n",
    "    A = zarr.open(zarr_array_path, mode='r')\n",
    "    data = A[subarray[0] : subarray[1], subarray[2] : subarray[3]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, we'll issue a read operation of a single cell `(100, 100)` of the array. Because both TileDB and Zarr are chunked data formats, reading a single cell will require reading the entire chunk of data containing the cell. Due to the variability of S3 performance we'll run 10 trials. Then we'll plot the comparison for all three tile configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cell_read_times = {'tiledb': [], 'zarr': []}\n",
    "subarray = (100, 101, 100, 101)\n",
    "for t_ext in tile_extents:\n",
    "    remove_arrays()\n",
    "    write_2d_tiledb_array(array_data, t_ext)\n",
    "    write_2d_zarr_array(array_data, t_ext)\n",
    "    single_cell_read_times['tiledb'].append(min(timeit(lambda: read_tiledb_2d_subarray(subarray), repeat=10)))\n",
    "    single_cell_read_times['zarr'].append(min(timeit(lambda: read_zarr_2d_subarray(subarray), repeat=10)))\n",
    "\n",
    "plot_bars(single_cell_read_times, 'S3 single-cell read time (2D, slice {}:{}, {}:{})'.format(*subarray), \n",
    "          'Tile extent', 'Time (sec)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interpret above results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll issue read operations of a large slice of array data. We'll specify a subarray large enough to intersect all 4 of the largest tile size, and plot the comparison for all three tile configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subarray_read_times = {'tiledb': [], 'zarr': []}\n",
    "subarray = (1000, 6001, 1000, 6001)\n",
    "for t_ext in tile_extents:\n",
    "    remove_arrays()\n",
    "    write_2d_tiledb_array(array_data, t_ext)\n",
    "    write_2d_zarr_array(array_data, t_ext)\n",
    "    subarray_read_times['tiledb'].append(min(timeit(lambda: read_tiledb_2d_subarray(subarray), repeat=5)))\n",
    "    subarray_read_times['zarr'].append(min(timeit(lambda: read_zarr_2d_subarray(subarray), repeat=5)))\n",
    "\n",
    "plot_bars(subarray_read_times, 'S3 multi-cell read time (2D, slice {}:{}, {}:{})'.format(*subarray), \n",
    "          'Tile extent', 'Time (sec)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interpret above resutls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Results\n",
    "\n",
    "First, we'll modify the TileDB and Zarr paths to point to a local paths rooted at a directory on the SSD. We'll also configure TileDB to use a single-threaded configuration, to avoid excessive disk contention by multiple parallel I/O operations.\n",
    "\n",
    "We'll then simply repeat the same experiments as with S3, but now measuring the time when the array data resides on a local disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_root_dir = '/ssd'\n",
    "tiledb_array_path = os.path.join(array_root_dir, tiledb_array_name)\n",
    "zarr_array_path = os.path.join(array_root_dir, zarr_array_name)\n",
    "\n",
    "config = tiledb.Config()\n",
    "config['sm.num_tbb_threads'] = 1\n",
    "config['vfs.num_threads'] = 1\n",
    "\n",
    "\n",
    "def drop_fs_cache():\n",
    "    \"Drops the OS filesystem cache(s).\"\n",
    "    # On macOS: subprocess.call(['sudo', 'purge'])\n",
    "    subprocess.call(['sudo', 'sh', '-c', 'echo 3 >/proc/sys/vm/drop_caches'])\n",
    "    \n",
    "    \n",
    "def remove_arrays():\n",
    "    \"Remove any persisted arrays.\"\n",
    "    for array in [tiledb_array_path, zarr_array_path]:\n",
    "        if os.path.exists(array):\n",
    "            shutil.rmtree(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array creation\n",
    "\n",
    "Below are the times for creating the array on the local SSD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_creation_times = {'tiledb': [], 'zarr': []}\n",
    "tile_extents = [(1000, 1000), (3000, 3000), (5000, 5000)]\n",
    "for t_ext in tile_extents:\n",
    "    array_creation_times['tiledb'].append(\n",
    "        min(timeit(lambda: write_2d_tiledb_array(array_data, t_ext), setup=remove_arrays, repeat=3)))\n",
    "    array_creation_times['zarr'].append(\n",
    "        min(timeit(lambda: write_2d_zarr_array(array_data, t_ext), setup=remove_arrays, repeat=3)))\n",
    "\n",
    "plot_bars(array_creation_times, 'Array creation time (2D, size {})'.format(num_array_values),\n",
    "          'Tile extent', 'Time (sec)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interpret results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read performance\n",
    "\n",
    "Next we'll repeat the single-cell and subarray reads, now reading from the array on local disk. Note that we add a call to drop the FS caches, which will occur before each read operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cell_read_times = {'tiledb': [], 'zarr': []}\n",
    "subarray = (100, 101, 100, 101)\n",
    "for t_ext in tile_extents:\n",
    "    remove_arrays()\n",
    "    write_2d_tiledb_array(array_data, t_ext)\n",
    "    write_2d_zarr_array(array_data, t_ext)\n",
    "    single_cell_read_times['tiledb'].append(min(timeit(lambda: read_tiledb_2d_subarray(subarray), setup=drop_fs_cache, repeat=5)))\n",
    "    single_cell_read_times['zarr'].append(min(timeit(lambda: read_zarr_2d_subarray(subarray), setup=drop_fs_cache, repeat=5)))\n",
    "\n",
    "plot_bars(single_cell_read_times, 'Single-cell read time (2D, slice {}:{}, {}:{})'.format(*subarray), \n",
    "          'Tile extent', 'Time (sec)')\n",
    "\n",
    "subarray_read_times = {'tiledb': [], 'zarr': []}\n",
    "subarray = (1000, 6001, 1000, 6001)\n",
    "for t_ext in tile_extents:\n",
    "    remove_arrays()\n",
    "    write_2d_tiledb_array(array_data, t_ext)\n",
    "    write_2d_zarr_array(array_data, t_ext)\n",
    "    subarray_read_times['tiledb'].append(min(timeit(lambda: read_tiledb_2d_subarray(subarray), setup=drop_fs_cache, repeat=5)))\n",
    "    subarray_read_times['zarr'].append(min(timeit(lambda: read_zarr_2d_subarray(subarray), setup=drop_fs_cache, repeat=5)))\n",
    "\n",
    "plot_bars(subarray_read_times, 'Multi-cell read time (2D, slice {}:{}, {}:{})'.format(*subarray), \n",
    "          'Tile extent', 'Time (sec)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_array_values = 100000000\n",
    "array_data = np.random.rand(num_array_values)\n",
    "print('Array data is {:.2f} MB uncompressed.'.format(array_data.nbytes / (1024 * 1024.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define some new helper functions to create persistent 1D arrays with a given tile or chunk size, and to remove all three arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_1d_tiledb_array(array_data, tile_extent):\n",
    "    ctx = tiledb.Ctx(config)\n",
    "    dom = tiledb.Domain(ctx, tiledb.Dim(ctx, domain=(0, num_array_values - 1),\n",
    "                                        tile=tile_extent, dtype=np.uint32))\n",
    "    schema = tiledb.ArraySchema(ctx, domain=dom, sparse=False,\n",
    "                                attrs=[tiledb.Attr(ctx, name='a', dtype=np.float64, compressor=tiledb_compressor)])\n",
    "    tiledb.DenseArray.create(tiledb_array_path, schema)\n",
    "    with tiledb.DenseArray(ctx, tiledb_array_path, mode='w') as A:\n",
    "        A[:] = array_data\n",
    "    sync_fs()\n",
    "\n",
    "\n",
    "def write_1d_bcolz_array(array_data, tile_extent):\n",
    "    A = bcolz.carray(array_data, rootdir=bcolz_array_path, mode='w', chunklen=tile_extent)\n",
    "    A.flush()\n",
    "    sync_fs()\n",
    "\n",
    "\n",
    "def write_1d_zarr_array(array_data, tile_extent):\n",
    "    A = zarr.open(zarr_array_path, mode='w', compressor=zarr_compressor, shape=array_data.shape, chunks=(tile_extent,),\n",
    "                  dtype=np.float64)\n",
    "    A[:] = array_data\n",
    "    sync_fs()\n",
    "    \n",
    "def remove_arrays():\n",
    "    \"Remove any persisted arrays.\"\n",
    "    for array in [tiledb_array_path, bcolz_array_path, zarr_array_path]:\n",
    "        if os.path.exists(array):\n",
    "            shutil.rmtree(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll persist the array data separately using each library and plot the minimum time over 3 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_creation_times = {'tiledb': [], 'zarr': [], 'bcolz': []}\n",
    "tile_extents = [100000, 1000000, 10000000]\n",
    "for t_ext in tile_extents:\n",
    "    array_creation_times['tiledb'].append(\n",
    "        min(timeit(lambda: write_1d_tiledb_array(array_data, t_ext), setup=remove_arrays, repeat=3)))\n",
    "    array_creation_times['zarr'].append(\n",
    "        min(timeit(lambda: write_1d_zarr_array(array_data, t_ext), setup=remove_arrays, repeat=3)))\n",
    "    array_creation_times['bcolz'].append(\n",
    "        min(timeit(lambda: write_1d_bcolz_array(array_data, t_ext), setup=remove_arrays, repeat=3)))\n",
    "\n",
    "plot_bars(array_creation_times, 'Array creation time (1D, size {})'.format(num_array_values),\n",
    "          'Tile extent', 'Time (sec)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interpret the above results: it's likely to be similar for all libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tiledb_1d_subarray(subarray):\n",
    "    ctx = tiledb.Ctx(config)\n",
    "    with tiledb.DenseArray(ctx, tiledb_array_path, mode='r') as A:\n",
    "        data = A[subarray[0] : subarray[1]]\n",
    "\n",
    "\n",
    "def read_bcolz_1d_subarray(subarray):\n",
    "    with bcolz.carray(rootdir=bcolz_array_path, mode='r') as A:\n",
    "        data = A[subarray[0] : subarray[1]]\n",
    "\n",
    "\n",
    "def read_zarr_1d_subarray(subarray):\n",
    "    A = zarr.open(zarr_array_path, mode='r')\n",
    "    data = A[subarray[0] : subarray[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll time and plot the results over 10 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cell_read_times = {'tiledb': [], 'zarr': [], 'bcolz': []}\n",
    "subarray = (100, 101)\n",
    "for t_ext in tile_extents:\n",
    "    remove_arrays()\n",
    "    write_1d_tiledb_array(array_data, t_ext)\n",
    "    write_1d_bcolz_array(array_data, t_ext)\n",
    "    write_1d_zarr_array(array_data, t_ext)\n",
    "    single_cell_read_times['tiledb'].append(min(timeit(lambda: read_tiledb_1d_subarray(subarray), setup=drop_fs_cache, repeat=5)))\n",
    "    single_cell_read_times['bcolz'].append(min(timeit(lambda: read_bcolz_1d_subarray(subarray), setup=drop_fs_cache, repeat=5)))\n",
    "    single_cell_read_times['zarr'].append(min(timeit(lambda: read_zarr_1d_subarray(subarray), setup=drop_fs_cache, repeat=5)))\n",
    "\n",
    "plot_bars(single_cell_read_times, 'Single-cell read time (1D, slice {}:{})'.format(*subarray), \n",
    "          'Tile extent', 'Time (sec)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interpret above results here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-cell reads\n",
    "\n",
    "next we'll repeat the above experiment but with a larger subarray slice. because each chunked format treats the chunk as the minimum I/O size, if the subarray slice is entirely within a single chunk/tile, the result will be the same as the single-cell result. so we'll pick a subarray slice equal to 5 of the largest tile size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subarray_read_times = {'tiledb': [], 'zarr': [], 'bcolz': []}\n",
    "subarray = (1000, 1000 + tile_extents[-1] + 1)\n",
    "for t_ext in tile_extents:\n",
    "    remove_arrays()\n",
    "    write_1d_tiledb_array(array_data, t_ext)\n",
    "    write_1d_bcolz_array(array_data, t_ext)\n",
    "    write_1d_zarr_array(array_data, t_ext)\n",
    "    subarray_read_times['tiledb'].append(min(timeit(lambda: read_tiledb_1d_subarray(subarray), setup=drop_fs_cache, repeat=5)))\n",
    "    subarray_read_times['bcolz'].append(min(timeit(lambda: read_bcolz_1d_subarray(subarray), setup=drop_fs_cache, repeat=5)))\n",
    "    subarray_read_times['zarr'].append(min(timeit(lambda: read_zarr_1d_subarray(subarray), setup=drop_fs_cache, repeat=5)))\n",
    "\n",
    "plot_bars(subarray_read_times, 'Multi-cell read time (1D, slice {}:{})'.format(*subarray),\n",
    "          'Tile extent', 'Time (sec)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interpret above results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
