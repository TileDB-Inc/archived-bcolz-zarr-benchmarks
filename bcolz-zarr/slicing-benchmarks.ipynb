{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "introduce the problem of storing multidimensional array data and accessing it efficiently.\n",
    "\n",
    "note that hdf5 is perhaps the most well-known solution, but there are newer alternatives designed from the start to integrate well with python data science pipelines.\n",
    "\n",
    "these days, focus is also shifting to how to store and access array data on the cloud, which presents different challenges.\n",
    "\n",
    "in this article we will compare TileDB to two python libraries for compressed, chunked array data storage and retrieval. the two libraries are bcolz and zarr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import bcolz\n",
    "import matplotlib.pyplot as plt\n",
    "import numcodecs\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import tiledb\n",
    "import time\n",
    "import zarr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-dimensional arrays\n",
    "\n",
    "we'll start with one-dimensional data, which will help us introduce the three libraries and get some initial understanding of their relative performance.\n",
    "\n",
    "the benchmark data will be an array of 8-byte floating point values stored initially in a numpy array. we'll use the three libraries to separately serialize the numpy array to disk.\n",
    "\n",
    "Note that because the data is random, we don't expect to see much gain with compression by either system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_array_values = 100000000\n",
    "array_data = np.random.rand(num_array_values)\n",
    "print('Array data is {:.2f} MB uncompressed.'.format(array_data.nbytes / (1024 * 1024.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we choose names for the arrays that will be stored on disk and choose a compressor setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiledb_array_name = 'tiledb_array'\n",
    "bcolz_array_name = 'bcolz_array'\n",
    "zarr_array_name = 'zarr_array'\n",
    "\n",
    "tiledb_compressor = ('blosc-lz4', 5)\n",
    "zarr_compressor = numcodecs.Blosc(cname='lz4', clevel=5)\n",
    "bcolz.defaults.cparams['cname'] = 'lz4'\n",
    "bcolz.defaults.cparams['clevel'] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define some helper functions to create persistent arrays with a given tile or chunk size, and also to remove the arrays.\n",
    "\n",
    "TileDB has the extra step of explicitly defining an `ArraySchema` which controls the domain of the array, its dimensionality, tiling strategy, and datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_1d_tiledb_array(array_data, tile_extent):\n",
    "    ctx = tiledb.Ctx()\n",
    "    dom = tiledb.Domain(ctx, tiledb.Dim(ctx, domain=(0, num_array_values - 1),\n",
    "                                        tile=tile_extent, dtype=np.uint32))\n",
    "    schema = tiledb.ArraySchema(ctx, domain=dom, sparse=False,\n",
    "                                attrs=[tiledb.Attr(ctx, name='a', dtype=np.float64, compressor=tiledb_compressor)])\n",
    "    tiledb.DenseArray.create(tiledb_array_name, schema)\n",
    "    with tiledb.DenseArray(ctx, tiledb_array_name, mode='w') as A:\n",
    "        A[:] = array_data\n",
    "\n",
    "\n",
    "def write_1d_bcolz_array(array_data, tile_extent):\n",
    "    A = bcolz.carray(array_data, rootdir=bcolz_array_name, mode='w', chunklen=tile_extent)\n",
    "    A.flush()\n",
    "\n",
    "\n",
    "def write_1d_zarr_array(array_data, tile_extent):\n",
    "    A = zarr.open(zarr_array_name, mode='w', compressor=zarr_compressor, shape=array_data.shape, chunks=(tile_extent,),\n",
    "                  dtype=np.float64)\n",
    "    A[:] = array_data\n",
    "    \n",
    "\n",
    "def remove_arrays():\n",
    "    for array in [tiledb_array_name, bcolz_array_name, zarr_array_name]:\n",
    "        if os.path.exists(array):\n",
    "            shutil.rmtree(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also define a helper function to time a function call a number of times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeit(fnc, setup=None, repeat=3):\n",
    "    times = []\n",
    "    for i in range(0, repeat):\n",
    "        if setup is not None:\n",
    "            setup()\n",
    "        start = time.time()\n",
    "        fnc()\n",
    "        end = time.time()\n",
    "        times.append(end - start)\n",
    "    return times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll persist the array data separately using each library and plot the minimum time over 3 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bars(times_per_library, title, xlabel, ylabel):\n",
    "    bar_width = 0.25\n",
    "    xpos1 = np.arange(len(times_per_library['tiledb']))\n",
    "    xpos2 = xpos1 + bar_width\n",
    "    xpos3 = xpos2 + bar_width\n",
    "    xpos = [xpos1, xpos2, xpos3]\n",
    "    \n",
    "    plt.figure()\n",
    "    for i, key in enumerate(sorted(times_per_library.keys())):\n",
    "        plt.bar(xpos[i], times_per_library[key], width=bar_width, label=key)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xticks(xpos1 + bar_width, tile_extents)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "array_creation_times = {'tiledb': [], 'zarr': [], 'bcolz': []}\n",
    "tile_extents = [100000, 1000000, 10000000]\n",
    "for t_ext in tile_extents:\n",
    "    array_creation_times['tiledb'].append(\n",
    "        min(timeit(lambda: write_1d_tiledb_array(array_data, t_ext), setup=remove_arrays, repeat=3)))\n",
    "    array_creation_times['zarr'].append(\n",
    "        min(timeit(lambda: write_1d_zarr_array(array_data, t_ext), setup=remove_arrays, repeat=3)))\n",
    "    array_creation_times['bcolz'].append(\n",
    "        min(timeit(lambda: write_1d_bcolz_array(array_data, t_ext), setup=remove_arrays, repeat=3)))\n",
    "    \n",
    "plot_bars(array_creation_times, 'Array creation time (1D, size {})'.format(num_array_values),\n",
    "          'Tile extent', 'Time (sec)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interpret the above results: it's likely to be similar for all libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-cell reads\n",
    "\n",
    "Next we'll examine how read performance varies with the tile/chunk size when reading a single value (cell) from the arrays.\n",
    "\n",
    "in general with all of these chunked formats, the main tuning parameter for read performance is controlling the chunk size. \n",
    "\n",
    "small chunk sizes are better for smaller reads (as a higher percentage of each chunk will contain values that intersect the region of the array being read), but can result in high overhead for large reads (due to many distinct i/o and decompression operations).\n",
    "\n",
    "large chunk sizes are better for larger reads due to better streaming i/o and decompression.\n",
    "\n",
    "so on the smallest extreme, reading a single cell, we expect to do better in all cases with the smaller chunk size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to begin with we'll define helper functions that read a specified region (\"subarray\") of the array for each library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tiledb_1d_subarray(subarray):\n",
    "    ctx = tiledb.Ctx()\n",
    "    with tiledb.DenseArray(ctx, tiledb_array_name, mode='r') as A:\n",
    "        data = A[subarray[0] : subarray[1]]\n",
    "\n",
    "\n",
    "def read_bcolz_1d_subarray(subarray):\n",
    "    with bcolz.carray(rootdir=bcolz_array_name, mode='r') as A:\n",
    "        data = A[subarray[0] : subarray[1]]\n",
    "\n",
    "\n",
    "def read_zarr_1d_subarray(subarray):\n",
    "    A = zarr.open(zarr_array_name, mode='r')\n",
    "    data = A[subarray[0] : subarray[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll time and plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cell_read_times = {'tiledb': [], 'zarr': [], 'bcolz': []}\n",
    "subarray = (100, 101)\n",
    "for t_ext in tile_extents:\n",
    "    remove_arrays()\n",
    "    write_1d_tiledb_array(array_data, t_ext)\n",
    "    write_1d_bcolz_array(array_data, t_ext)\n",
    "    write_1d_zarr_array(array_data, t_ext)\n",
    "    single_cell_read_times['tiledb'].append(min(timeit(lambda: read_tiledb_1d_subarray(subarray), repeat=3)))\n",
    "    single_cell_read_times['bcolz'].append(min(timeit(lambda: read_bcolz_1d_subarray(subarray), repeat=3)))\n",
    "    single_cell_read_times['zarr'].append(min(timeit(lambda: read_zarr_1d_subarray(subarray), repeat=3)))\n",
    "\n",
    "plot_bars(single_cell_read_times, 'Single-cell read time (1D, slice {}:{})'.format(*subarray), \n",
    "          'Tile extent', 'Time (sec)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interpret above results here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-cell reads\n",
    "\n",
    "next we'll repeat the above experiment but with a larger subarray slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subarray_read_times = {'tiledb': [], 'zarr': [], 'bcolz': []}\n",
    "subarray = (1000, 50001)\n",
    "for t_ext in tile_extents:\n",
    "    remove_arrays()\n",
    "    write_1d_tiledb_array(array_data, t_ext)\n",
    "    write_1d_bcolz_array(array_data, t_ext)\n",
    "    write_1d_zarr_array(array_data, t_ext)\n",
    "    subarray_read_times['tiledb'].append(min(timeit(lambda: read_tiledb_1d_subarray(subarray), repeat=3)))\n",
    "    subarray_read_times['bcolz'].append(min(timeit(lambda: read_bcolz_1d_subarray(subarray), repeat=3)))\n",
    "    subarray_read_times['zarr'].append(min(timeit(lambda: read_zarr_1d_subarray(subarray), repeat=3)))\n",
    "\n",
    "plot_bars(subarray_read_times, 'Multi-cell read time (1D, slice {}:{})'.format(*subarray),\n",
    "          'Tile extent', 'Time (sec)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interpret above results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi-dimensional arrays\n",
    "\n",
    "increased dimensionality of the data requires different design decisions.\n",
    "\n",
    "bcolz is not suitable for ND data, so we will omit it from here on out. this is because it can only chunk along one dimension, and thus will perform extremely poorly for nd slices.\n",
    "\n",
    "zarr supports chunking along multiple dimensions, as does tiledb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## array creation\n",
    "\n",
    "we'll start by creating some synthetic 2D data and writing the arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_array_values = 10000, 10000\n",
    "array_data = np.random.rand(*num_array_values)\n",
    "print('Array data is {:.2f} MB uncompressed.'.format(array_data.nbytes / (1024 * 1024.0)))\n",
    "\n",
    "\n",
    "def write_2d_tiledb_array(array_data, tile_extents):\n",
    "    shape = array_data.shape\n",
    "    ctx = tiledb.Ctx()\n",
    "    dom = tiledb.Domain(ctx,\n",
    "                        tiledb.Dim(ctx, domain=(0, shape[0] - 1), tile=tile_extents[0], dtype=np.uint32),\n",
    "                        tiledb.Dim(ctx, domain=(0, shape[1] - 1), tile=tile_extents[1], dtype=np.uint32))\n",
    "    schema = tiledb.ArraySchema(ctx, domain=dom, sparse=False,\n",
    "                                attrs=[tiledb.Attr(ctx, name='a', dtype=np.float64, compressor=tiledb_compressor)])\n",
    "    tiledb.DenseArray.create(tiledb_array_name, schema)\n",
    "    with tiledb.DenseArray(ctx, tiledb_array_name, mode='w') as A:\n",
    "        A[:] = array_data\n",
    "\n",
    "\n",
    "def write_2d_zarr_array(array_data, tile_extents):\n",
    "    A = zarr.open(zarr_array_name, mode='w', compressor=zarr_compressor, shape=array_data.shape, chunks=tile_extents,\n",
    "                  dtype=np.float64)\n",
    "    A[:] = array_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next we can time the array creation time for 2D arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_creation_times = {'tiledb': [], 'zarr': []}\n",
    "tile_extents = [(1000, 1000), (3000, 3000), (5000, 5000)]\n",
    "for t_ext in tile_extents:\n",
    "    array_creation_times['tiledb'].append(\n",
    "        min(timeit(lambda: write_2d_tiledb_array(array_data, t_ext), setup=remove_arrays, repeat=3)))\n",
    "    array_creation_times['zarr'].append(\n",
    "        min(timeit(lambda: write_2d_zarr_array(array_data, t_ext), setup=remove_arrays, repeat=3)))\n",
    "    \n",
    "plot_bars(array_creation_times, 'Array creation time (2D, size {})'.format(num_array_values),\n",
    "          'Tile extent', 'Time (sec)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interpret above results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## single-cell read\n",
    "\n",
    "to begin with we'll define similar helper functions which read a 2D subarray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tiledb_2d_subarray(subarray):\n",
    "    ctx = tiledb.Ctx()\n",
    "    with tiledb.DenseArray(ctx, tiledb_array_name, mode='r') as A:\n",
    "        data = A[subarray[0] : subarray[1], subarray[2] : subarray[3]]\n",
    "\n",
    "\n",
    "def read_zarr_2d_subarray(subarray):\n",
    "    A = zarr.open(zarr_array_name, mode='r')\n",
    "    data = A[subarray[0] : subarray[1], subarray[2] : subarray[3]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next we'll time and plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cell_read_times = {'tiledb': [], 'zarr': []}\n",
    "subarray = (100, 101, 100, 101)\n",
    "for t_ext in tile_extents:\n",
    "    remove_arrays()\n",
    "    write_2d_tiledb_array(array_data, t_ext)\n",
    "    write_2d_zarr_array(array_data, t_ext)\n",
    "    single_cell_read_times['tiledb'].append(min(timeit(lambda: read_tiledb_2d_subarray(subarray), repeat=3)))\n",
    "    single_cell_read_times['zarr'].append(min(timeit(lambda: read_zarr_2d_subarray(subarray), repeat=3)))\n",
    "\n",
    "plot_bars(single_cell_read_times, 'Single-cell read time (2D, slice {}:{}, {}:{})'.format(*subarray), \n",
    "          'Tile extent', 'Time (sec)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-cell reads\n",
    "\n",
    "next we'll repeat the above experiment but with a larger subarray slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subarray_read_times = {'tiledb': [], 'zarr': []}\n",
    "subarray = (1000, 5001, 1000, 5001)\n",
    "for t_ext in tile_extents:\n",
    "    remove_arrays()\n",
    "    write_2d_tiledb_array(array_data, t_ext)\n",
    "    write_2d_zarr_array(array_data, t_ext)\n",
    "    subarray_read_times['tiledb'].append(min(timeit(lambda: read_tiledb_2d_subarray(subarray), repeat=3)))\n",
    "    subarray_read_times['zarr'].append(min(timeit(lambda: read_zarr_2d_subarray(subarray), repeat=3)))\n",
    "\n",
    "plot_bars(subarray_read_times, 'Multi-cell read time (2D, slice {}:{}, {}:{})'.format(*subarray), \n",
    "          'Tile extent', 'Time (sec)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interpret above results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud storage\n",
    "\n",
    "so far all of the above comparisons have happened on local disk.\n",
    "\n",
    "we'll now repeat the 2D comparison with zarr, but the array will be persisted on an AWS S3 bucket.\n",
    "\n",
    "first some configuration, and we'll redefine `remove_arrays()` to be able to interact with S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "\n",
    "s3_bucket_name = 'tiledb-bench'\n",
    "\n",
    "\n",
    "def remove_arrays():\n",
    "    ctx = tiledb.Ctx()\n",
    "    vfs = tiledb.VFS(ctx)\n",
    "    tiledb_uri = 's3://{}/{}'.format(s3_bucket_name, tiledb_array_name)\n",
    "    zarr_uri = 's3://{}/{}'.format(s3_bucket_name, zarr_array_name)\n",
    "    if vfs.is_dir(tiledb_uri):\n",
    "        vfs.remove_dir(tiledb_uri)\n",
    "    if vfs.is_dir(zarr_uri):\n",
    "        vfs.remove_dir(zarr_uri)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next we'll swap out the array \"name\" variables so that both TileDB and Zarr direct their operations to arrays on S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zarr_s3 = s3fs.S3FileSystem(key=os.environ['AWS_ACCESS_KEY_ID'],\n",
    "                            secret=os.environ['AWS_SECRET_ACCESS_KEY'])\n",
    "zarr_s3_store = s3fs.S3Map(root=s3_bucket_name + '/' + zarr_array_name,\n",
    "                           s3=zarr_s3, check=False)\n",
    "zarr_array_name = zarr_s3_store\n",
    "tiledb_array_name = 's3://{}/{}'.format(s3_bucket_name, tiledb_array_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array creation\n",
    "\n",
    "first up we'll repeat the array creation tests, now on S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_creation_times = {'tiledb': [], 'zarr': []}\n",
    "for t_ext in tile_extents:\n",
    "    array_creation_times['tiledb'].append(\n",
    "        min(timeit(lambda: write_2d_tiledb_array(array_data, t_ext), setup=remove_arrays, repeat=3)))\n",
    "    array_creation_times['zarr'].append(\n",
    "        min(timeit(lambda: write_2d_zarr_array(array_data, t_ext), setup=remove_arrays, repeat=3)))\n",
    "    \n",
    "plot_bars(array_creation_times, 'S3 array creation time (2D, size {})'.format(num_array_values),\n",
    "          'Tile extent', 'Time (sec)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interpret above results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## single-cell read\n",
    "\n",
    "next we'll repeat the single-cell reads on S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cell_read_times = {'tiledb': [], 'zarr': []}\n",
    "subarray = (100, 101, 100, 101)\n",
    "for t_ext in tile_extents:\n",
    "    remove_arrays()\n",
    "    write_2d_tiledb_array(array_data, t_ext)\n",
    "    write_2d_zarr_array(array_data, t_ext)\n",
    "    single_cell_read_times['tiledb'].append(min(timeit(lambda: read_tiledb_2d_subarray(subarray), repeat=3)))\n",
    "    single_cell_read_times['zarr'].append(min(timeit(lambda: read_zarr_2d_subarray(subarray), repeat=3)))\n",
    "\n",
    "plot_bars(single_cell_read_times, 'S3 single-cell read time (2D, slice {}:{}, {}:{})'.format(*subarray), \n",
    "          'Tile extent', 'Time (sec)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interpret above results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multi-cell read\n",
    "\n",
    "finally we'll repeat the multi-cell reads on S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subarray_read_times = {'tiledb': [], 'zarr': []}\n",
    "subarray = (1000, 5001, 1000, 5001)\n",
    "for t_ext in tile_extents:\n",
    "    remove_arrays()\n",
    "    write_2d_tiledb_array(array_data, t_ext)\n",
    "    write_2d_zarr_array(array_data, t_ext)\n",
    "    subarray_read_times['tiledb'].append(min(timeit(lambda: read_tiledb_2d_subarray(subarray), repeat=3)))\n",
    "    subarray_read_times['zarr'].append(min(timeit(lambda: read_zarr_2d_subarray(subarray), repeat=3)))\n",
    "\n",
    "plot_bars(subarray_read_times, 'S3 multi-cell read time (2D, slice {}:{}, {}:{})'.format(*subarray), \n",
    "          'Tile extent', 'Time (sec)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interpret above resutls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
